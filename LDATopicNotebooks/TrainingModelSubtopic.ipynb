{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgxUlprEhrRe"
      },
      "outputs": [],
      "source": [
        "from gensim.models import LdaModel\n",
        "import gensim\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import spacy\n",
        "import gc\n",
        "from gensim.test.utils import datapath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "AVj8U_K9lQFb",
        "outputId": "c17656b0-33d6-4964-c10c-ddd06dd4e1fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "With 0.7 confidence, retaining only 0.8999959009913745 %\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quoteId</th>\n",
              "      <th>lemmas</th>\n",
              "      <th>stems</th>\n",
              "      <th>geoNames</th>\n",
              "      <th>score</th>\n",
              "      <th>topic</th>\n",
              "      <th>spectrum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-15-001323</td>\n",
              "      <td>['start', 'new', 'tradition', 'field', 'stream...</td>\n",
              "      <td>[start, new, tradit, field, stream, shop, pass...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.765691</td>\n",
              "      <td>politics&amp;biz&amp;tech</td>\n",
              "      <td>{'politics&amp;biz&amp;tech': 0.7656912803649902, 'spo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-15-001439</td>\n",
              "      <td>['current', 'allegation', 'misrepresentation',...</td>\n",
              "      <td>[current, alleg, misrepresent, primari, goal, ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.955535</td>\n",
              "      <td>politics&amp;biz&amp;tech</td>\n",
              "      <td>{'politics&amp;biz&amp;tech': 0.9555345000699162, 'spo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2016-01-15-001063</td>\n",
              "      <td>['debate', 'troop', 'afghanistan', 'go', 'reop...</td>\n",
              "      <td>[debat, troop, afghanistan, go, reopen]</td>\n",
              "      <td>['US', 'Afghanistan']</td>\n",
              "      <td>0.759259</td>\n",
              "      <td>politics&amp;biz&amp;tech</td>\n",
              "      <td>{'politics&amp;biz&amp;tech': 0.7592592481523752, 'spo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2016-01-15-001143</td>\n",
              "      <td>['reemergence', 'afghanistan', 'issue']</td>\n",
              "      <td>[reemerg, afghanistan, issu]</td>\n",
              "      <td>['Afghanistan']</td>\n",
              "      <td>0.638896</td>\n",
              "      <td>politics&amp;biz&amp;tech</td>\n",
              "      <td>{'politics&amp;biz&amp;tech': 0.6388958431780338, 'spo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2016-01-15-001107</td>\n",
              "      <td>['james', 'madison', 'visit', 'professorship',...</td>\n",
              "      <td>[jame, madison, visit, professorship, amend, i...</td>\n",
              "      <td>[]</td>\n",
              "      <td>0.650817</td>\n",
              "      <td>politics&amp;biz&amp;tech</td>\n",
              "      <td>{'politics&amp;biz&amp;tech': 0.6508172042667866, 'spo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             quoteId  ...                                           spectrum\n",
              "0  2016-01-15-001323  ...  {'politics&biz&tech': 0.7656912803649902, 'spo...\n",
              "2  2016-01-15-001439  ...  {'politics&biz&tech': 0.9555345000699162, 'spo...\n",
              "5  2016-01-15-001063  ...  {'politics&biz&tech': 0.7592592481523752, 'spo...\n",
              "6  2016-01-15-001143  ...  {'politics&biz&tech': 0.6388958431780338, 'spo...\n",
              "7  2016-01-15-001107  ...  {'politics&biz&tech': 0.6508172042667866, 'spo...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#import the train dataset\n",
        "df = pd.read_csv('politics_biz_tech_quotes.csv.gz')\n",
        "\n",
        "#getting back the list \n",
        "from ast import literal_eval\n",
        "df['stems'] = df.apply(lambda x: literal_eval(x['stems']), axis = 1)\n",
        "df['stems'].head()\n",
        "\n",
        "#estricting the train dataset to one topic\n",
        "pol = df[df['topic'] == 'politics&biz&tech'  ]\n",
        "#retaining only those with high confidence\n",
        "print('With 0.5 confidence, retaining only', len(pol[pol.score >0.5])/len(pol),'%')\n",
        "pol.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HHR4BiJjjtp",
        "outputId": "b421556e-2022-415e-9820-2045c21b9a54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_df:  409855 train_corpus 409855\n",
            "test_df:  102464 test_corpus 102464\n"
          ]
        }
      ],
      "source": [
        "#import the dictionary\n",
        "dictionary_10 = gensim.corpora.Dictionary.load('1_layer_model.txt.id2word')\n",
        "\n",
        "#make the corpus\n",
        "rate = int(len(pol)*0.8)\n",
        "train_df = pol.iloc[:rate]\n",
        "test_df = pol.iloc[rate:]\n",
        "train_corpus = [dictionary_10.doc2bow(doc) for doc in train_df.stems.values]\n",
        "test_corpus = [dictionary_10.doc2bow(doc) for doc in test_df.stems.values]\n",
        "print('train_df: ', len(train_df), 'train_corpus', len(train_corpus))\n",
        "print('test_df: ', len(test_df), 'test_corpus', len(test_corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozp1npSXgW0T",
        "outputId": "a0a8f6fa-147d-48a7-f25c-34b415fcd7bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0,\n",
            "  '0.018*\"need\" + 0.014*\"peopl\" + 0.012*\"govern\" + 0.011*\"issu\" + '\n",
            "  '0.010*\"system\" + 0.009*\"problem\" + 0.008*\"secur\" + 0.007*\"concern\" + '\n",
            "  '0.007*\"countri\" + 0.007*\"health\"'),\n",
            " (1,\n",
            "  '0.026*\"work\" + 0.022*\"great\" + 0.018*\"peopl\" + 0.015*\"famili\" + '\n",
            "  '0.013*\"commun\" + 0.012*\"school\" + 0.011*\"want\" + 0.011*\"year\" + '\n",
            "  '0.009*\"help\" + 0.009*\"life\"'),\n",
            " (2,\n",
            "  '0.044*\"go\" + 0.032*\"think\" + 0.032*\"like\" + 0.030*\"know\" + 0.029*\"want\" + '\n",
            "  '0.026*\"peopl\" + 0.025*\"thing\" + 0.017*\"time\" + 0.015*\"come\" + 0.015*\"say\"'),\n",
            " (3,\n",
            "  '0.014*\"new\" + 0.013*\"busi\" + 0.012*\"year\" + 0.008*\"market\" + '\n",
            "  '0.008*\"develop\" + 0.008*\"compani\" + 0.006*\"product\" + 0.006*\"build\" + '\n",
            "  '0.006*\"continu\" + 0.006*\"high\"'),\n",
            " (4,\n",
            "  '0.028*\"state\" + 0.012*\"court\" + 0.012*\"law\" + 0.010*\"offic\" + 0.010*\"decis\" '\n",
            "  '+ 0.009*\"case\" + 0.009*\"presid\" + 0.009*\"polic\" + 0.009*\"unit\" + '\n",
            "  '0.008*\"govern\"'),\n",
            " (5,\n",
            "  '0.018*\"woman\" + 0.012*\"fight\" + 0.012*\"man\" + 0.010*\"campaign\" + '\n",
            "  '0.010*\"trump\" + 0.009*\"say\" + 0.009*\"polit\" + 0.008*\"peopl\" + 0.008*\"speak\" '\n",
            "  '+ 0.008*\"candid\"'),\n",
            " (6,\n",
            "  '0.018*\"life\" + 0.016*\"live\" + 0.012*\"love\" + 0.010*\"stori\" + 0.010*\"like\" + '\n",
            "  '0.009*\"music\" + 0.008*\"film\" + 0.008*\"write\" + 0.008*\"old\" + 0.008*\"year\"'),\n",
            " (7,\n",
            "  '0.032*\"play\" + 0.030*\"good\" + 0.024*\"game\" + 0.022*\"get\" + 0.020*\"team\" + '\n",
            "  '0.018*\"think\" + 0.017*\"year\" + 0.016*\"win\" + 0.014*\"go\" + 0.013*\"player\"'),\n",
            " (8,\n",
            "  '0.017*\"parti\" + 0.015*\"vote\" + 0.014*\"question\" + 0.012*\"ask\" + '\n",
            "  '0.008*\"south\" + 0.008*\"water\" + 0.007*\"minist\" + 0.007*\"new\" + 0.007*\"come\" '\n",
            "  '+ 0.006*\"answer\"')]\n"
          ]
        }
      ],
      "source": [
        "#check on the baseline lda model being used\n",
        "from gensim.test.utils import datapath\n",
        "from pprint import pprint\n",
        "temp_lda = LdaModel.load('1_layer_model.txt')\n",
        "pprint(temp_lda.print_topics())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfGTtkolhzgp",
        "outputId": "f561903e-5561-4d4f-a963-97a7d8224d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################\n",
            "N_topics:\t 4\n",
            "Coherence_train:\t 0.40363980986328296\n",
            "Coherence_test:\t 0.37056612240811865\n",
            "###################\n",
            "N_topics:\t 5\n",
            "Coherence_train:\t 0.40190590141345134\n",
            "Coherence_test:\t 0.3850878906817027\n",
            "###################\n",
            "N_topics:\t 6\n",
            "Coherence_train:\t 0.4172401046563407\n",
            "Coherence_test:\t 0.39500101084866585\n"
          ]
        }
      ],
      "source": [
        "n_topics_to_try = [4, 5, 6] \n",
        "lda_models = []\n",
        "for n in n_topics_to_try:\n",
        "  train_model =  gensim.models.LdaMulticore(train_corpus, \n",
        "                                    num_topics = n, \n",
        "                                    id2word = dictionary_10,                                    \n",
        "                                    passes = 10,\n",
        "                                    alpha = 0.001,\n",
        "                                    workers = 5)\n",
        "  #save the model to file\n",
        "  temp_file = datapath(\"./2_layer_model\"+str(n))\n",
        "  train_model.save(\"1_layer_model\"+str(n)+\".txt\")\n",
        "  lda_models.append(train_model)\n",
        "  #compute metrics\n",
        "  coherence_train = CoherenceModel(model=train_model, texts=train_df.stems.values, dictionary=dictionary_10, coherence='c_v')\n",
        "  coherence_train = coherence_train.get_coherence()\n",
        "  coherence_test = CoherenceModel(model=train_model, texts=test_df.stems.values, dictionary=dictionary_10, coherence='c_v')\n",
        "  coherence_test = coherence_test.get_coherence()\n",
        "  print('###################')\n",
        "  print('N_topics:\\t', n)\n",
        "  print('Coherence_train:\\t', coherence_train)\n",
        "  print('Coherence_test:\\t', coherence_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bDm7VahorcO",
        "outputId": "b8cc6f95-6f6b-4fe3-94ab-b4328cb6eb32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################\n",
            "N_topics:\t 7\n",
            "Coherence_train:\t 0.4817316083656948\n",
            "Coherence_test:\t 0.4583992125523017\n",
            "###################\n",
            "N_topics:\t 8\n",
            "Coherence_train:\t 0.4869139428337849\n",
            "Coherence_test:\t 0.4435242418396107\n",
            "###################\n",
            "N_topics:\t 9\n",
            "Coherence_train:\t 0.49759265710935374\n",
            "Coherence_test:\t 0.47577877610542785\n"
          ]
        }
      ],
      "source": [
        "n_topics_to_try = [7, 8, 9]\n",
        "for n in n_topics_to_try:\n",
        "  train_model =  gensim.models.LdaMulticore(train_corpus, \n",
        "                                    num_topics = n, \n",
        "                                    id2word = dictionary_10,                                    \n",
        "                                    passes = 10,\n",
        "                                    alpha = 0.001,\n",
        "                                    workers = 5)\n",
        "  #save the model to file\n",
        "  temp_file = datapath(\"./2_layer_model\"+str(n))\n",
        "  train_model.save(\"1_layer_model\"+str(n)+\".txt\")\n",
        "  lda_models.append(train_model)\n",
        "  #compute metrics\n",
        "  coherence_train = CoherenceModel(model=train_model, texts=train_df.stems.values, dictionary=dictionary_10, coherence='c_v')\n",
        "  coherence_train = coherence_train.get_coherence()\n",
        "  coherence_test = CoherenceModel(model=train_model, texts=test_df.stems.values, dictionary=dictionary_10, coherence='c_v')\n",
        "  coherence_test = coherence_test.get_coherence()\n",
        "  print('###################')\n",
        "  print('N_topics:\\t', n)\n",
        "  print('Coherence_train:\\t', coherence_train)\n",
        "  print('Coherence_test:\\t', coherence_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLUZrozHpiNu",
        "outputId": "8846ba33-9fb9-45ba-884c-1ce3064e9c12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################\n",
            "N_topics:\t 20\n",
            "Coherence_train:\t 0.5291168052327155\n",
            "Coherence_test:\t 0.47003389878826096\n",
            "###################\n",
            "N_topics:\t 30\n",
            "Coherence_train:\t 0.47302952264310877\n",
            "Coherence_test:\t 0.4374878364580619\n"
          ]
        }
      ],
      "source": [
        "n_topics_to_try = [20, 30]\n",
        "for n in n_topics_to_try:\n",
        "  train_model =  gensim.models.LdaMulticore(train_corpus, \n",
        "                                    num_topics = n, \n",
        "                                    id2word = dictionary_10,                                    \n",
        "                                    passes = 10,\n",
        "                                    alpha = 0.001,\n",
        "                                    workers = 5)\n",
        "  #save the model to file\n",
        "  temp_file = datapath(\"./2_layer_model\"+str(n))\n",
        "  train_model.save(\"1_layer_model\"+str(n)+\".txt\")\n",
        "  lda_models.append(train_model)\n",
        "  #compute metrics\n",
        "  coherence_train = CoherenceModel(model=train_model, texts=train_df.stems.values, dictionary=dictionary_10, coherence='c_v')\n",
        "  coherence_train = coherence_train.get_coherence()\n",
        "  coherence_test = CoherenceModel(model=train_model, texts=test_df.stems.values, dictionary=dictionary_10, coherence='c_v')\n",
        "  coherence_test = coherence_test.get_coherence()\n",
        "  print('###################')\n",
        "  print('N_topics:\\t', n)\n",
        "  print('Coherence_train:\\t', coherence_train)\n",
        "  print('Coherence_test:\\t', coherence_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzhaV2HcgISL",
        "outputId": "1e87fab1-222b-4a23-9132-ab78cd3f61a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################\n",
            "N_topics:\t 15\n",
            "Coherence_train:\t 0.5556450955862073\n",
            "Coherence_test:\t 0.5000772783501467\n",
            "###################\n",
            "N_topics:\t 25\n",
            "Coherence_train:\t 0.5213544194659454\n",
            "Coherence_test:\t 0.4454921089975931\n"
          ]
        }
      ],
      "source": [
        "n_topics_to_try = [15, 25]\n",
        "lda_models = []\n",
        "for n in n_topics_to_try:\n",
        "  train_model =  gensim.models.LdaMulticore(train_corpus, \n",
        "                                    num_topics = n, \n",
        "                                    id2word = dictionary_10,                                    \n",
        "                                    passes = 10,\n",
        "                                    workers = 5)\n",
        "  #save the model to file\n",
        "  temp_file = datapath(\"./2_layer_model\"+str(n))\n",
        "  train_model.save(\"1_layer_model\"+str(n)+\".txt\")\n",
        "  lda_models.append(train_model)\n",
        "  #compute metrics\n",
        "  coherence_train = CoherenceModel(model=train_model, texts=train_df.stems.values, dictionary=dictionary_10, coherence='c_v')\n",
        "  coherence_train = coherence_train.get_coherence()\n",
        "  coherence_test = CoherenceModel(model=train_model, texts=test_df.stems.values, dictionary=dictionary_10, coherence='c_v')\n",
        "  coherence_test = coherence_test.get_coherence()\n",
        "  print('###################')\n",
        "  print('N_topics:\\t', n)\n",
        "  print('Coherence_train:\\t', coherence_train)\n",
        "  print('Coherence_test:\\t', coherence_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Mi4pmbYEyoq",
        "outputId": "c010450b-f3dd-486a-aa26-7e6ea1b559c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "###################\n",
            "N_topics:\t 10\n",
            "Coherence_train:\t 0.5211101649056407\n",
            "Coherence_test:\t 0.4741554900816647\n",
            "###################\n",
            "N_topics:\t 12\n",
            "Coherence_train:\t 0.5327665367666964\n",
            "Coherence_test:\t 0.4818774490373609\n",
            "###################\n",
            "N_topics:\t 17\n",
            "Coherence_train:\t 0.5466070181812305\n",
            "Coherence_test:\t 0.4734530859832064\n",
            "###################\n",
            "N_topics:\t 22\n",
            "Coherence_train:\t 0.5416167440363293\n",
            "Coherence_test:\t 0.47076413495714353\n",
            "###################\n",
            "N_topics:\t 25\n",
            "Coherence_train:\t 0.51155527113694\n",
            "Coherence_test:\t 0.44446176773356894\n"
          ]
        }
      ],
      "source": [
        "n_topics_to_try = [10, 12, 17, 22, 25]\n",
        "lda_models = []\n",
        "for n in n_topics_to_try:\n",
        "  train_model =  gensim.models.LdaMulticore(train_corpus, \n",
        "                                    num_topics = n, \n",
        "                                    id2word = dictionary_10,                                    \n",
        "                                    passes = 10,\n",
        "                                    workers = 5)\n",
        "  #save the model to file\n",
        "  temp_file = datapath(\"./2_layer_model\"+str(n))\n",
        "  train_model.save(\"1_layer_model\"+str(n)+\".txt\")\n",
        "  lda_models.append(train_model)\n",
        "  #compute metrics\n",
        "  coherence_train = CoherenceModel(model=train_model, texts=train_df.stems.values, dictionary=dictionary_10, coherence='c_v')\n",
        "  coherence_train = coherence_train.get_coherence()\n",
        "  coherence_test = CoherenceModel(model=train_model, texts=test_df.stems.values, dictionary=dictionary_10, coherence='c_v')\n",
        "  coherence_test = coherence_test.get_coherence()\n",
        "  print('###################')\n",
        "  print('N_topics:\\t', n)\n",
        "  print('Coherence_train:\\t', coherence_train)\n",
        "  print('Coherence_test:\\t', coherence_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "TrainingModelSubtopic.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
